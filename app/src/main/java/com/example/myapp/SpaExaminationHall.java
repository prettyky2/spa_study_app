package com.example.myapp;

import android.content.Intent;
import android.content.pm.PackageManager;
import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.Image;
import android.media.MediaRecorder;
import android.os.Bundle;
import android.os.CountDownTimer;

import android.util.Log;

import java.io.InputStream;
import java.util.List;
import java.util.concurrent.Executors;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.TimeUnit;
import java.io.FileInputStream;

import android.Manifest;

import android.util.TypedValue;
import android.view.View;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.TextView;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.TextView;
import android.media.MediaPlayer;

import androidx.appcompat.app.AppCompatActivity;
import androidx.activity.EdgeToEdge;
import androidx.constraintlayout.widget.ConstraintLayout;
import androidx.core.content.ContextCompat;
import androidx.core.graphics.Insets;
import androidx.core.view.ViewCompat;
import androidx.core.view.WindowInsetsCompat;
import androidx.core.graphics.Insets;
import androidx.core.view.ViewCompat;
import androidx.core.view.WindowInsetsCompat;

import com.google.auth.oauth2.GoogleCredentials;

import com.google.protobuf.ByteString;
import com.google.android.material.progressindicator.LinearProgressIndicator;
import com.google.api.gax.rpc.StreamController;
import com.google.api.gax.rpc.ResponseObserver;
import com.google.api.gax.rpc.BidiStreamingCallable;
import com.google.api.gax.rpc.ApiStreamObserver;
import com.google.cloud.speech.v1.SpeechClient;
import com.google.cloud.speech.v1.StreamingRecognizeRequest;
import com.google.cloud.speech.v1.StreamingRecognizeResponse;
import com.google.cloud.speech.v1.StreamingRecognitionConfig;
import com.google.cloud.speech.v1.StreamingRecognitionResult;
import com.google.cloud.speech.v1.RecognitionConfig;

import io.grpc.stub.StreamObserver;

import com.google.api.gax.rpc.BidiStreamingCallable;
import com.google.api.gax.rpc.ApiStreamObserver;
import io.grpc.stub.StreamObserver;
import com.google.cloud.speech.v1.*;

public class SpaExaminationHall extends AppApplication implements View.OnClickListener {

    private static final String TAG = "spaExaminationHall";
    private TextView questionNumber = null;
    private LinearProgressIndicator progressBar;
    private Button playPause = null;
    private Button playNext = null;
    private ImageView viewImage = null;
    private MediaPlayer mediaPlayer;
    private CountDownTimer timer;
    private TextView userAnswer = null;
    private int testNum = 0;
    private int currentIndex = 1;
    private int remainingTime = 120;
    private boolean isPaused = false;
    private boolean isMediaPlaying = false;
    private boolean isMediaPlayNow = false;
    private MediaRecorder recorder;
    private SpeechClient speechClient;
    private boolean isListening = false;
    private ScheduledExecutorService executorService;
    private ResponseObserver<StreamingRecognizeResponse> responseObserver;
    private ApiStreamObserver<StreamingRecognizeRequest> requestObserver;
    private String answer_1 = null;
    private String answer_2 = null;
    private String answer_3 = null;
    private String answer_4 = null;
    private String lastRecognizedText = ""; // ğŸ”¹ ë§ˆì§€ë§‰ìœ¼ë¡œ ì¸ì‹ëœ ë¬¸ì¥ì„ ì €ì¥
    private ConstraintLayout dailySpaExaminationHallUserAnswer;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        EdgeToEdge.enable(this);
        setContentView(R.layout.activity_spa_examination_hall);
        ViewCompat.setOnApplyWindowInsetsListener(findViewById(R.id.spa_examination_hall_activity), (v, insets) -> {
            Insets systemBars = insets.getInsets(WindowInsetsCompat.Type.systemBars());
            v.setPadding(systemBars.left, systemBars.top, systemBars.right, systemBars.bottom);
            return insets;
        });

        initializeClass();
        startPlayback();

    } //onCreate()

    @Override
    public void onClick(View v) {
        if(v.getId() == R.id.btn_play_pause) {
            togglePause();
        } else if (v.getId() == R.id.btn_play_next) {
            skipToNext();
        }
    } //onClick();

    private void initializeClass() {
        // Intentì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ -1 ì„¤ì •: ê°’ì´ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
        testNum = getIntent().getIntExtra("test_num", -1);

        questionNumber = findViewById(R.id.daily_spa_examination_question_number);
        progressBar = findViewById(R.id.progress_bar);
        progressBar.setProgress(0);
        playPause = findViewById(R.id.btn_play_pause);
        playNext = findViewById(R.id.btn_play_next);
        viewImage = findViewById(R.id.image_view);
        userAnswer = findViewById(R.id.daily_spa_examination_hall_user_answer);

        playPause.setOnClickListener(this);
        playNext.setOnClickListener(this);
        viewImage.setOnClickListener(this);
        userAnswer.setOnClickListener(this);

        updateQuestionTextImage();
        viewImage.setVisibility(View.GONE);

    }

    private void startPlayback() {
        if (testNum == -1 || currentIndex > 4) return;

        updateUILayout(); // ğŸ”¹ UI ë³€ê²½ ë°˜ì˜

        if(currentIndex ==  4) {
            viewImage.setVisibility(View.VISIBLE);
            // ğŸ”¹ ë™ì ìœ¼ë¡œ ì´ë¯¸ì§€ ë¦¬ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
            String resourceName = "spa_test_" + testNum;
            int resId = getResources().getIdentifier(resourceName, "drawable", getPackageName());

            if (resId != 0) {
                viewImage.setImageResource(resId);
            } else {
                Log.e(TAG, "Invalid resource: " + resourceName);
            }
        }


        String fileName = "spa_test_" + testNum + "_" + currentIndex;
        int resId = getResources().getIdentifier(fileName, "raw", getPackageName());

        if (resId == 0) return;

        if (mediaPlayer != null) {
            mediaPlayer.release();
        }
        mediaPlayer = MediaPlayer.create(this, resId);
        mediaPlayer.setOnCompletionListener(mp -> {
            isMediaPlaying = false;
            isMediaPlayNow = false;
            startCountdown();
        });
        mediaPlayer.start();
        isMediaPlaying = true;
        isMediaPlayNow = true;
    }

    private void startCountdown() {
        if (timer != null) {
            timer.cancel();
        }

        progressBar.setProgress(0); // ë‹¤ìŒ ë¬¸ì œë¡œ ë„˜ì–´ê°ˆ ë•Œ í”„ë¡œê·¸ë˜ìŠ¤ë°” ì´ˆê¸°í™”
        startSpeechRecognition(); // ìŒì„± ì¸ì‹ ì‹œì‘

        timer = new CountDownTimer(remainingTime * 1000L, 1000) {
            @Override
            public void onTick(long millisUntilFinished) {
                remainingTime = (int) (millisUntilFinished / 1000);
                progressBar.setProgress(100 - (int) ((remainingTime / 120.0) * 100)); // ì™¼ìª½ë¶€í„° ê°ì†Œ
                if (remainingTime <= 10) {
                    playPause.setEnabled(false);
                    playNext.setEnabled(false);
                }
            }

            @Override
            public void onFinish() {
                Log.d(TAG, "Countdown finished. Stopping speech recognition.");

                stopSpeechRecognition(); // âœ… ìŒì„± ì¸ì‹ ì¢…ë£Œ
                saveUserAnswer(); // âœ… ì €ì¥
                runOnUiThread(() -> userAnswer.setText("")); // âœ… userAnswer ì´ˆê¸°í™”

                if (currentIndex == 4) {
                    finish(); // ë§ˆì§€ë§‰ íŒŒì¼ ì¬ìƒ í›„ ì•¡í‹°ë¹„í‹° ì¢…ë£Œ
                } else {
                    currentIndex++;
                    remainingTime = 120;
                    playPause.setEnabled(true);
                    playNext.setEnabled(true);
                    updateQuestionTextImage();
                    progressBar.setProgress(0); // ë‹¤ìŒ ë¬¸ì œë¡œ ë„˜ì–´ê°ˆ ë•Œ í”„ë¡œê·¸ë˜ìŠ¤ë°” ì´ˆê¸°í™”
                    startPlayback();
                }
            }
        };
        timer.start();
    }

    private void startSpeechRecognition() {
        try {
            Log.d(TAG, "Starting speech recognition...");

            // âœ… ì¸ì¦ ì •ë³´ ë¡œë“œ
            InputStream credentialsStream = getResources().openRawResource(R.raw.spastudyproject_key);
            GoogleCredentials credentials = GoogleCredentials.fromStream(credentialsStream);

            // âœ… SpeechClientë¥¼ ìƒì„±í•  ë•Œ ì¸ì¦ ì •ë³´ ì„¤ì •
            SpeechSettings speechSettings = SpeechSettings.newBuilder()
                    .setCredentialsProvider(() -> credentials)
                    .build();
            speechClient = SpeechClient.create(speechSettings);

            // âœ… responseObserverë¥¼ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ (ApiStreamObserver ì‚¬ìš©)
            ApiStreamObserver<StreamingRecognizeResponse> responseObserver = new ApiStreamObserver<StreamingRecognizeResponse>() {
                @Override
                public void onNext(StreamingRecognizeResponse response) {
                    for (StreamingRecognitionResult result : response.getResultsList()) {
                        String transcript = result.getAlternatives(0).getTranscript();
                        Log.d(TAG, "Recognized speech: " + transcript);

                        runOnUiThread(() -> {
                            if (!result.getIsFinal()) {
                                // ğŸ”¹ ì¤‘ê°„ ê²°ê³¼ë„ ëˆ„ì í•´ì„œ í‘œì‹œ
                                userAnswer.setText(lastRecognizedText + " " + transcript);
                            } else {
                                // ğŸ”¹ ìµœì¢… ê²°ê³¼ í™•ì • ì‹œ ëˆ„ì  ê°±ì‹ 
                                lastRecognizedText += " " + transcript;
                                lastRecognizedText = lastRecognizedText.trim();
                                userAnswer.setText(lastRecognizedText);
                            }
                        });


                    }
                }

                @Override
                public void onError(Throwable t) {
                    Log.e(TAG, "Speech recognition error: " + t.getMessage(), t);
                }

                @Override
                public void onCompleted() {
                    Log.d(TAG, "Speech recognition completed.");
                }
            };

            // âœ… `bidiStreamingCall()`ì„ ì˜¬ë°”ë¥´ê²Œ í˜¸ì¶œ
            BidiStreamingCallable<StreamingRecognizeRequest, StreamingRecognizeResponse> callable =
                    speechClient.streamingRecognizeCallable();

            // âœ… requestObserverì˜ íƒ€ì…ì„ ì˜¬ë°”ë¥´ê²Œ ì„¤ì • (ê°•ì œ ìºìŠ¤íŒ… ì œê±°)
            requestObserver = callable.bidiStreamingCall(responseObserver);

            // âœ… ìŒì„± ì¸ì‹ ì„¤ì • êµ¬ì„±
            RecognitionConfig config = RecognitionConfig.newBuilder()
                    .setEncoding(RecognitionConfig.AudioEncoding.LINEAR16)
                    .setSampleRateHertz(16000)
                    .setLanguageCode("en-US")
                    .build();

            StreamingRecognitionConfig streamingConfig = StreamingRecognitionConfig.newBuilder()
                    .setConfig(config)
                    .setInterimResults(true)
                    .build();

            StreamingRecognizeRequest request = StreamingRecognizeRequest.newBuilder()
                    .setStreamingConfig(streamingConfig)
                    .build();

            // âœ… ìš”ì²­ì„ ì „ì†¡
            requestObserver.onNext(request);
            Log.d(TAG, "Streaming recognition request sent.");

            isListening = true;

            // âœ… ìŒì„± ì…ë ¥ì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤ë ˆë“œ ì‹¤í–‰
            executorService = Executors.newSingleThreadScheduledExecutor();
            executorService.scheduleAtFixedRate(this::streamAudio, 0, 100, TimeUnit.MILLISECONDS);

        } catch (Exception e) {
            Log.e(TAG, "Error starting speech recognition", e);
        }
    }

    private void streamAudio() {
        if (!isListening) return; // âœ… ìŒì„± ì¸ì‹ì´ ì¤‘ë‹¨ëœ ê²½ìš° ì‹¤í–‰í•˜ì§€ ì•ŠìŒ

        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            Log.e(TAG, "Microphone permission is not granted!");
            return;
        }

        if (requestObserver == null) {
            Log.e(TAG, "Speech recognition request observer is null!");
            return;
        }

        try {
            AudioRecord audioRecord = new AudioRecord(
                    MediaRecorder.AudioSource.MIC,
                    16000,
                    AudioFormat.CHANNEL_IN_MONO,
                    AudioFormat.ENCODING_PCM_16BIT,
                    AudioRecord.getMinBufferSize(16000, AudioFormat.CHANNEL_IN_MONO, AudioFormat.ENCODING_PCM_16BIT)
            );

            audioRecord.startRecording();
            Log.d(TAG, "Audio recording started.");

            byte[] buffer = new byte[4096];

            while (isListening) {
                int bytesRead = audioRecord.read(buffer, 0, buffer.length);
                if (bytesRead > 0 && requestObserver != null) {
                    try {
                        StreamingRecognizeRequest request = StreamingRecognizeRequest.newBuilder()
                                .setAudioContent(ByteString.copyFrom(buffer, 0, bytesRead))
                                .build();
                        requestObserver.onNext(request);
                    } catch (Exception e) {
                        Log.e(TAG, "Error sending audio data", e);
                        break; // âœ… ì˜ˆì™¸ ë°œìƒ ì‹œ ë£¨í”„ ì¢…ë£Œ
                    }
                }
            }

            audioRecord.stop();
            audioRecord.release();
            Log.d(TAG, "Audio recording stopped.");

        } catch (Exception e) {
            Log.e(TAG, "Error in streamAudio", e);
        }
    }

    private void stopSpeechRecognition() {
        Log.d(TAG, "Stopping speech recognition...");

        isListening = false; // âœ… ìŒì„± ì¸ì‹ ì¤‘ì§€ ìƒíƒœë¡œ ë³€ê²½

        if (requestObserver != null) {
            try {
                requestObserver.onCompleted();
                Log.d(TAG, "Request observer completed.");
            } catch (Exception e) {
                Log.e(TAG, "Error completing request observer", e);
            }
            requestObserver = null; // âœ… ìš”ì²­ ì˜µì €ë²„ë¥¼ nullë¡œ ì„¤ì •í•˜ì—¬ ì´í›„ ë°ì´í„° ì „ì†¡ ë°©ì§€
        }
        if (speechClient != null) {
            try {
                speechClient.close();
                speechClient = null;
                Log.d(TAG, "Speech client closed.");
            } catch (Exception e) {
                Log.e(TAG, "Error closing speech client", e);
            }
        }
        if (executorService != null) {
            executorService.shutdown();
            executorService = null;
            Log.d(TAG, "Executor service shut down.");
        }
    }

    private void togglePause() {
        if (isMediaPlayNow) {
            if (isMediaPlaying) {
                mediaPlayer.pause();
                isMediaPlaying = false;
            } else {
                mediaPlayer.start();
                isMediaPlaying = true;
            }
        } else if (timer != null) {
            if (isPaused) {
                startCountdown();
            } else {
                timer.cancel();
            }
            isPaused = !isPaused;
        }
    }

    private void skipToNext() {
        if (currentIndex == 4) {
            finish();
            return;
        }

        // ìŒì„± ì¸ì‹ ì¢…ë£Œ ë° í…ìŠ¤íŠ¸ ì €ì¥
        stopSpeechRecognition(); // âœ… ìŒì„± ì¸ì‹ ì¢…ë£Œ
        saveUserAnswer(); // âœ… ì €ì¥
        runOnUiThread(() -> userAnswer.setText("")); // âœ… userAnswer ì´ˆê¸°í™”

        // ë¯¸ë””ì–´ê°€ ì¬ìƒ ì¤‘ì´ë©´ ì •ì§€
        if (mediaPlayer != null && isMediaPlaying) {
            mediaPlayer.stop();
            mediaPlayer.release();
            mediaPlayer = null;
            isMediaPlaying = false;
        }

        // íƒ€ì´ë¨¸ê°€ ì¡´ì¬í•˜ë©´ ì •ì§€
        if (timer != null) {
            timer.cancel();
        }

        // ë‚¨ì€ ì‹œê°„ì„ ì´ˆê¸°í™”
        remainingTime = 120;

        // ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ì´ë™
        currentIndex++;
        updateQuestionTextImage();

        // í”„ë¡œê·¸ë˜ìŠ¤ë°” ì´ˆê¸°í™”
        progressBar.setProgress(0);

        // ë‹¤ìŒ ì§ˆë¬¸ì˜ ë¯¸ë””ì–´ë¥¼ ì¬ìƒ
        startPlayback();
    }

    // ì‚¬ìš©ìì˜ ìŒì„± ì¸ì‹ ê²°ê³¼ ì €ì¥
    private void saveUserAnswer() {
        String answer = lastRecognizedText.trim(); // ğŸ”¹ ìµœì¢… ì¸ì‹ëœ ë¬¸ì¥ì„ ì €ì¥
        Log.d(TAG, "Saving user answer: " + answer);

        if (!answer.isEmpty()) {
            switch (currentIndex) {
                case 1:
                    answer_1 = answer;
                    break;
                case 2:
                    answer_2 = answer;
                    break;
                case 3:
                    answer_3 = answer;
                    break;
                case 4:
                    answer_4 = answer;
                    break;
                default:
                    Log.e(TAG, "Invalid currentIndex: " + currentIndex);
                    return;
            }

            // âœ… ì €ì¥ëœ ë‚´ìš©ì„ ë¡œê·¸ë¡œ ì¶œë ¥
            Log.d(TAG, "Answer saved -> answer_1: " + answer_1
                    + ", answer_2: " + answer_2
                    + ", answer_3: " + answer_3
                    + ", answer_4: " + answer_4);
        }

        lastRecognizedText = "";
    }

    private void updateQuestionTextImage() {
        int questionResId = getResources().getIdentifier("spa_test_question_" + currentIndex, "string", getPackageName());
        if (questionResId != 0) {
            questionNumber.setText(questionResId);
        }
        if(currentIndex == 4) {

        }
    }

    private void updateUILayout() {
        ConstraintLayout.LayoutParams userAnswerParams =
                (ConstraintLayout.LayoutParams) userAnswer.getLayoutParams();
        ConstraintLayout.LayoutParams imageParams =
                (ConstraintLayout.LayoutParams) viewImage.getLayoutParams();

        if (currentIndex == 4) {
            // ğŸ”¹ daily_spa_examination_hall_user_answer ë†’ì´ 50dp ì„¤ì •
            userAnswerParams.height = (int) TypedValue.applyDimension(
                    TypedValue.COMPLEX_UNIT_DIP, 50, getResources().getDisplayMetrics());

            // ğŸ”¹ ê¸°ì¡´ bottom constraint í•´ì œ
            userAnswerParams.bottomToBottom = ConstraintLayout.LayoutParams.UNSET;

            // ğŸ”¹ viewImageë¥¼ daily_spa_examination_hall_user_answer ì•„ë˜ë¡œ ë°°ì¹˜
            imageParams.topToBottom = userAnswer.getId();
        } else {
            // ğŸ”¹ ê¸°ì¡´ ìƒíƒœë¡œ ë³µêµ¬
            userAnswerParams.height = ConstraintLayout.LayoutParams.MATCH_CONSTRAINT;
            userAnswerParams.bottomToBottom = ConstraintLayout.LayoutParams.PARENT_ID;
            imageParams.topToBottom = ConstraintLayout.LayoutParams.UNSET;
        }

        // ğŸ”¹ ë³€ê²½ ì‚¬í•­ ì ìš©
        userAnswer.setLayoutParams(userAnswerParams);
        viewImage.setLayoutParams(imageParams);
    }

    @Override
    protected void onPause() {
        super.onPause();

        // ë¯¸ë””ì–´ê°€ ì¬ìƒ ì¤‘ì´ë©´ ì •ì§€ ë° í•´ì œ
        if (mediaPlayer != null) {
            if (isMediaPlaying) {
                mediaPlayer.stop();
                isMediaPlaying = false;
            }
            mediaPlayer.release();
            mediaPlayer = null;
        }

        // íƒ€ì´ë¨¸ê°€ ì‹¤í–‰ ì¤‘ì´ë©´ ì •ì§€
        if (timer != null) {
            timer.cancel();
            timer = null;
        }

        stopSpeechRecognition();
        Log.d(TAG, "onPause: Stopping all media and speech recognition.");

        // ì•¡í‹°ë¹„í‹° ì¢…ë£Œ
        finish();
    }

}
